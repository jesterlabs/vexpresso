{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88f5cb6-2b03-418a-b726-faca6dbe8427",
   "metadata": {},
   "source": [
    "# Querying Audio with CLAP embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21c7d4-859d-405f-a06e-8f00b898703e",
   "metadata": {},
   "source": [
    "## In this walkthrough, we will be using a dataset of audio files and embed them using the CLAP model (https://huggingface.co/docs/transformers/v4.30.0/en/model_doc/clap#transformers.ClapModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19c592-79a2-46c4-807f-0288742cb1fc",
   "metadata": {},
   "source": [
    "## Installation Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abc2f21-388b-419f-a26f-2619c262e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shyam/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor, ClapModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import vexpresso\n",
    "from vexpresso.utils import ResourceRequest, DataType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b775fd6-a215-464b-a22e-1963865e32b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f8cff-0a6f-47b6-8438-5bde8d8f6c8e",
   "metadata": {},
   "source": [
    "Here we load a dataset of audio files from https://huggingface.co/datasets/ashraq/esc50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e44af8a-8a2b-45a3-9e6f-9aabc16833a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/shyam/.cache/huggingface/datasets/ashraq___parquet/ashraq--esc50-1000c3b73cc1500f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 171.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"ashraq/esc50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8981da-90ea-4ae0-a6ed-134211b76ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = dataset['train']['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d88d35f8-294b-45cb-b060-a42f7fbfdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dataset['train'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6347940d-0ccc-4817-b4d0-f2a7135a2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['audio'] = audios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b69bb4f-441e-4194-badc-c0911541b5b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4e094-c89b-4639-9b37-afbba213fbf0",
   "metadata": {},
   "source": [
    "Lets create a collection with the audios that we downloaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edcaf55-588b-4939-bf71-26f52f409574",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = vexpresso.create(data=dictionary, backend=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "311da8f6-41e9-4a18-a3c6-770a0724ca8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <table class=\"dataframe\">\n",
       "<thead>\n",
       "<tr><th>filename<br>Utf8  </th><th style=\"text-align: right;\">  fold<br>Int64</th><th style=\"text-align: right;\">  target<br>Int64</th><th>category<br>Utf8  </th><th>esc10<br>Boolean  </th><th style=\"text-align: right;\">  src_file<br>Int64</th><th>take<br>Utf8  </th><th>audio<br>Struct[array: List[item:Float64], path: Null, sampling_rate: Int64]  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>1-100032-A-0.wav  </td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">                0</td><td>dog               </td><td>true              </td><td style=\"text-align: right;\">             100032</td><td>A             </td><td>{&#x27;array&#x27;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...        </td></tr>\n",
       "<tr><td>1-100038-A-14.wav </td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">               14</td><td>chirping_birds    </td><td>false             </td><td style=\"text-align: right;\">             100038</td><td>A             </td><td>{&#x27;array&#x27;: [-0.0118408203125, -0.103363037109375, -0.14141...        </td></tr>\n",
       "<tr><td>1-100210-A-36.wav </td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">               36</td><td>vacuum_cleaner    </td><td>false             </td><td style=\"text-align: right;\">             100210</td><td>A             </td><td>{&#x27;array&#x27;: [-0.0069580078125, -0.01251220703125, -0.011260...        </td></tr>\n",
       "<tr><td>1-100210-B-36.wav </td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">               36</td><td>vacuum_cleaner    </td><td>false             </td><td style=\"text-align: right;\">             100210</td><td>B             </td><td>{&#x27;array&#x27;: [0.538970947265625, 0.396270751953125, 0.267395...        </td></tr>\n",
       "<tr><td>1-101296-A-19.wav </td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">               19</td><td>thunderstorm      </td><td>false             </td><td style=\"text-align: right;\">             101296</td><td>A             </td><td>{&#x27;array&#x27;: [-0.0003662109375, -0.000701904296875, -0.00079...        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    <small>(Showing first 5 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "+-------------------+---------+----------+----------------+-----------+------------+--------+-----------------------------------------------------------------------+\n",
       "| filename          |    fold |   target | category       | esc10     |   src_file | take   | audio                                                                 |\n",
       "| Utf8              |   Int64 |    Int64 | Utf8           | Boolean   |      Int64 | Utf8   | Struct[array: List[item:Float64], path: Null, sampling_rate: Int64]   |\n",
       "+===================+=========+==========+================+===========+============+========+=======================================================================+\n",
       "| 1-100032-A-0.wav  |       1 |        0 | dog            | true      |     100032 | A      | {'array': [0.0, 0.0,                                                  |\n",
       "|                   |         |          |                |           |            |        | 0.0, 0.0, 0.0, 0.0,                                                   |\n",
       "|                   |         |          |                |           |            |        | 0.0, 0.0, 0.0, 0...                                                   |\n",
       "+-------------------+---------+----------+----------------+-----------+------------+--------+-----------------------------------------------------------------------+\n",
       "| 1-100038-A-14.wav |       1 |       14 | chirping_birds | false     |     100038 | A      | {'array':                                                             |\n",
       "|                   |         |          |                |           |            |        | [-0.0118408203125,                                                    |\n",
       "|                   |         |          |                |           |            |        | -0.103363037109375,                                                   |\n",
       "|                   |         |          |                |           |            |        | -0.14141...                                                           |\n",
       "+-------------------+---------+----------+----------------+-----------+------------+--------+-----------------------------------------------------------------------+\n",
       "| 1-100210-A-36.wav |       1 |       36 | vacuum_cleaner | false     |     100210 | A      | {'array':                                                             |\n",
       "|                   |         |          |                |           |            |        | [-0.0069580078125,                                                    |\n",
       "|                   |         |          |                |           |            |        | -0.01251220703125,                                                    |\n",
       "|                   |         |          |                |           |            |        | -0.011260...                                                          |\n",
       "+-------------------+---------+----------+----------------+-----------+------------+--------+-----------------------------------------------------------------------+\n",
       "| 1-100210-B-36.wav |       1 |       36 | vacuum_cleaner | false     |     100210 | B      | {'array':                                                             |\n",
       "|                   |         |          |                |           |            |        | [0.538970947265625,                                                   |\n",
       "|                   |         |          |                |           |            |        | 0.396270751953125,                                                    |\n",
       "|                   |         |          |                |           |            |        | 0.267395...                                                           |\n",
       "+-------------------+---------+----------+----------------+-----------+------------+--------+-----------------------------------------------------------------------+\n",
       "| 1-101296-A-19.wav |       1 |       19 | thunderstorm   | false     |     101296 | A      | {'array':                                                             |\n",
       "|                   |         |          |                |           |            |        | [-0.0003662109375,                                                    |\n",
       "|                   |         |          |                |           |            |        | -0.000701904296875,                                                   |\n",
       "|                   |         |          |                |           |            |        | -0.00079...                                                           |\n",
       "+-------------------+---------+----------+----------------+-----------+------------+--------+-----------------------------------------------------------------------+\n",
       "(Showing first 5 rows)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "950127c9-1c3c-438c-a3b5-8d58dd874a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <table class=\"dataframe\">\n",
       "<thead>\n",
       "<tr><th>path<br>Null  </th><th style=\"text-align: right;\">  sampling_rate<br>Int64</th><th>array<br>Python                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>None          </td><td style=\"text-align: right;\">                   44100</td><td>&ltnp.ndarray<br>shape=(220500,)<br>dtype=float64&gt</td></tr>\n",
       "<tr><td>None          </td><td style=\"text-align: right;\">                   44100</td><td>&ltnp.ndarray<br>shape=(220500,)<br>dtype=float64&gt</td></tr>\n",
       "<tr><td>None          </td><td style=\"text-align: right;\">                   44100</td><td>&ltnp.ndarray<br>shape=(220500,)<br>dtype=float64&gt</td></tr>\n",
       "<tr><td>None          </td><td style=\"text-align: right;\">                   44100</td><td>&ltnp.ndarray<br>shape=(220500,)<br>dtype=float64&gt</td></tr>\n",
       "<tr><td>None          </td><td style=\"text-align: right;\">                   44100</td><td>&ltnp.ndarray<br>shape=(220500,)<br>dtype=float64&gt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    <small>(Showing first 5 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "+--------+-----------------+---------------------+\n",
       "| path   |   sampling_rate | array               |\n",
       "| Null   |           Int64 | Python              |\n",
       "+========+=================+=====================+\n",
       "| None   |           44100 | [0. 0. 0. ... 0. 0. |\n",
       "|        |                 | 0.]                 |\n",
       "+--------+-----------------+---------------------+\n",
       "| None   |           44100 | [-0.01184082        |\n",
       "|        |                 | -0.10336304         |\n",
       "|        |                 | -0.14141846 ...     |\n",
       "|        |                 | 0.06985474  0.0...  |\n",
       "+--------+-----------------+---------------------+\n",
       "| None   |           44100 | [-0.00695801        |\n",
       "|        |                 | -0.01251221         |\n",
       "|        |                 | -0.01126099 ...     |\n",
       "|        |                 | 0.215271   -0.0...  |\n",
       "+--------+-----------------+---------------------+\n",
       "| None   |           44100 | [0.53897095         |\n",
       "|        |                 | 0.39627075          |\n",
       "|        |                 | 0.26739502 ...      |\n",
       "|        |                 | 0.09729004          |\n",
       "|        |                 | 0.112274...         |\n",
       "+--------+-----------------+---------------------+\n",
       "| None   |           44100 | [-0.00036621        |\n",
       "|        |                 | -0.0007019          |\n",
       "|        |                 | -0.00079346 ...     |\n",
       "|        |                 | 0.00317383  0.0...  |\n",
       "+--------+-----------------+---------------------+\n",
       "(Showing first 5 rows)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540216d-edef-42f5-89b8-703271c500f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multimodal CLAP Embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "902202bf-1650-4c0e-b0ce-5862cf24e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClAPEmbeddingsFunction:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "        self.processor = AutoProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "        self.device = torch.device('cpu')\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "            self.model = self.model.to(self.device)\n",
    "\n",
    "    def __call__(self, inp, inp_type):\n",
    "        if inp_type == \"audio\":\n",
    "            inputs = self.processor(audios=inp, return_tensors=\"pt\", padding=True)\n",
    "            print(inputs.keys())\n",
    "            for k in inputs:\n",
    "                inputs[k] = inputs[k].to(self.device)\n",
    "            return self.model.get_audio_features(**inputs).detach().cpu().numpy()\n",
    "        if inp_type == \"text\":\n",
    "            inputs = self.tokenizer(inp, padding=True, return_tensors=\"pt\")\n",
    "            inputs[\"input_ids\"] = inputs[\"input_ids\"].to(self.device)\n",
    "            inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(self.device)\n",
    "            return self.model.get_text_features(**inputs).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fbfbcfb-5657-4c2a-b1d4-dff96dec1534",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clap \u001b[38;5;241m=\u001b[39m \u001b[43mClAPEmbeddingsFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m, in \u001b[0;36mClAPEmbeddingsFunction.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/modeling_utils.py:1886\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1883\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1884\u001b[0m     )\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1886\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "clap = ClAPEmbeddingsFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0b839-3b50-4c81-a8e7-349a29d55201",
   "metadata": {},
   "source": [
    "## Now lets embed the audio arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e6dd029-7b13-4d91-8fed-58b548e9367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_features', 'is_longer'])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 3.82 GiB total capacity; 1.97 GiB already allocated; 156.44 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio_embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/vexpresso/daft/collection.py:145\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_daft_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdaft_df\u001b[38;5;241m.\u001b[39mcollect())\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DaftCollection:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_pandas\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/vexpresso/daft/collection.py:142\u001b[0m, in \u001b[0;36mcollect\u001b[0;34m(self, in_place)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_place:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdaft_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdaft_df\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_daft_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdaft_df\u001b[38;5;241m.\u001b[39mcollect())\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/api_annotations.py:23\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m type_check_function(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     22\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/analytics.py:184\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    186\u001b[0m     _ANALYTICS_CLIENT\u001b[38;5;241m.\u001b[39mtrack_df_method_call(\n\u001b[1;32m    187\u001b[0m         method_name\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, duration_seconds\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    188\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/dataframe/dataframe.py:951\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, num_preview_rows)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;129m@DataframePublicAPI\u001b[39m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_preview_rows: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    940\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the entire DataFrame and materializes the results\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m    .. NOTE::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;124;03m        DataFrame: DataFrame with materialized results.\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_materialize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    954\u001b[0m     dataframe_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/dataframe/dataframe.py:933\u001b[0m, in \u001b[0;36mDataFrame._materialize_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m context \u001b[38;5;241m=\u001b[39m get_context()\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/runners/pyrunner.py:192\u001b[0m, in \u001b[0;36mPyRunner.run\u001b[0;34m(self, logplan)\u001b[0m\n\u001b[1;32m    189\u001b[0m plan \u001b[38;5;241m=\u001b[39m physical_plan_factory\u001b[38;5;241m.\u001b[39mget_materializing_physical_plan(logplan, psets)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profiler(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile_PyRunner.run_\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mdatetime.now().isoformat()}.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 192\u001b[0m     partitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_physical_plan_to_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     result_pset \u001b[38;5;241m=\u001b[39m LocalPartitionSet({})\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, partition \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(partitions):\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/runners/pyrunner.py:259\u001b[0m, in \u001b[0;36mPyRunner._physical_plan_to_partitions\u001b[0;34m(self, plan)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inflight_tasks_resources[done_id]\n\u001b[1;32m    258\u001b[0m done_task \u001b[38;5;241m=\u001b[39m inflight_tasks\u001b[38;5;241m.\u001b[39mpop(done_id)\n\u001b[0;32m--> 259\u001b[0m partitions \u001b[38;5;241m=\u001b[39m \u001b[43mdone_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask completed: \u001b[39m\u001b[38;5;132;01m{done_id}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{partitions}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, done_id\u001b[38;5;241m=\u001b[39mdone_id, partitions\u001b[38;5;241m=\u001b[39mpartitions\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    264\u001b[0m done_task\u001b[38;5;241m.\u001b[39mset_result([PyMaterializedResult(partition) \u001b[38;5;28;01mfor\u001b[39;00m partition \u001b[38;5;129;01min\u001b[39;00m partitions])\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/concurrent/futures/_base.py:433\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/concurrent/futures/thread.py:52\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/runners/pyrunner.py:299\u001b[0m, in \u001b[0;36mPyRunner.build_partitions\u001b[0;34m(instruction_stack, *inputs)\u001b[0m\n\u001b[1;32m    297\u001b[0m partitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(inputs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instruction \u001b[38;5;129;01min\u001b[39;00m instruction_stack:\n\u001b[0;32m--> 299\u001b[0m     partitions \u001b[38;5;241m=\u001b[39m \u001b[43minstruction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m partitions\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/execution/execution_step.py:383\u001b[0m, in \u001b[0;36mProject.run\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: \u001b[38;5;28mlist\u001b[39m[Table]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Table]:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/execution/execution_step.py:387\u001b[0m, in \u001b[0;36mProject._project\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_project\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: \u001b[38;5;28mlist\u001b[39m[Table]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Table]:\n\u001b[1;32m    386\u001b[0m     [\u001b[38;5;28minput\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_expression_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojection\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/table/table.py:214\u001b[0m, in \u001b[0;36mTable.eval_expression_list\u001b[0;34m(self, exprs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(e, Expression) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m exprs)\n\u001b[1;32m    213\u001b[0m pyexprs \u001b[38;5;241m=\u001b[39m [e\u001b[38;5;241m.\u001b[39m_expr \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m exprs]\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Table\u001b[38;5;241m.\u001b[39m_from_pytable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_expression_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyexprs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/daft/udf.py:67\u001b[0m, in \u001b[0;36mPartialUDF.__call__\u001b[0;34m(self, evaluated_expressions)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# NOTE: We currently initialize the function once for every invocation of the PartialUDF.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# This is not ideal and we should cache initializations across calls for the same process.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mudf\u001b[38;5;241m.\u001b[39mget_initialized_func()\n\u001b[0;32m---> 67\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# HACK: Series have names and the logic for naming fields/series in a UDF is to take the first\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Expression's name. Note that this logic is tied to the `to_field` implementation of the Rust PythonUDF\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# and is quite error prone! If our Series naming logic here is wrong, things will break when the UDF is run on a table.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m name \u001b[38;5;241m=\u001b[39m evaluated_expressions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/vexpresso/utils.py:116\u001b[0m, in \u001b[0;36mtransform_wrapper.<locals>._Transformation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m args \u001b[38;5;241m=\u001b[39m convert_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    115\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m convert_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m, in \u001b[0;36mClAPEmbeddingsFunction.__call__\u001b[0;34m(self, inp, inp_type)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m     18\u001b[0m         inputs[k] \u001b[38;5;241m=\u001b[39m inputs[k]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_audio_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inp_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     21\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(inp, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:2054\u001b[0m, in \u001b[0;36mClapModel.get_audio_features\u001b[0;34m(self, input_features, is_longer, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2049\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2050\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   2051\u001b[0m )\n\u001b[1;32m   2052\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 2054\u001b[0m audio_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_longer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_longer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m audio_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m audio_outputs\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m   2062\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_projection(pooled_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:1758\u001b[0m, in \u001b[0;36mClapAudioModel.forward\u001b[0;34m(self, input_features, is_longer, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1753\u001b[0m output_attentions \u001b[38;5;241m=\u001b[39m output_attentions \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_attentions\n\u001b[1;32m   1754\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1755\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1756\u001b[0m )\n\u001b[0;32m-> 1758\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_longer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_longer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:921\u001b[0m, in \u001b[0;36mClapAudioEncoder.forward\u001b[0;34m(self, input_features, is_longer, head_mask, output_attentions, output_hidden_states, output_hidden_states_before_downsampling, always_partition, return_dict)\u001b[0m\n\u001b[1;32m    917\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape_mel2img(normalized_input_features)\n\u001b[1;32m    919\u001b[0m frames_num \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 921\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_longer_list_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m all_hidden_states \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    924\u001b[0m all_reshaped_hidden_states \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/transformers/models/clap/modeling_clap.py:394\u001b[0m, in \u001b[0;36mClapAudioPatchEmbed.forward\u001b[0;34m(self, hidden_states, is_longer_idx)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten:\n\u001b[1;32m    393\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 394\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/functional.py:2515\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2514\u001b[0m     )\n\u001b[0;32m-> 2515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 3.82 GiB total capacity; 1.97 GiB already allocated; 156.44 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "collection = collection.embed(\"array\", inp_type=\"audio\", embedding_fn=clap, to=\"audio_embeddings\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eacc00-c137-4754-82fe-2e69367ecf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f1b5e58-14ed-4465-a889-7e61eab73e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_features', 'is_longer'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clap(audio_sample, \"audio\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39] *",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
